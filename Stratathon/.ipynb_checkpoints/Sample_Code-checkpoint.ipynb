{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "from IPython.display import HTML\n",
    "import statsmodels.formula.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "apiKey = 'lQg24SpLGpWSL3Yn35VS'\n",
    "plotly.tools.set_credentials_file(username='amcdonne', api_key=apiKey)\n",
    "plotly.tools.set_config_file(world_readable=False, sharing='private')\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 1000)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "Ensemble ML using a group of weak classifers to determine class based on vote\n",
    "1. Standardize the variables\n",
    "2. Split the training and testing data for all the features and the classifier\n",
    "\n",
    "```python\n",
    "# Split the data into training and testing sets; set random state to a fixed number while testing \n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)\n",
    "#look at the shape to make sure everything matches up\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)\n",
    "```\n",
    "\n",
    "4. Baseline model: Generate one to see if the model beats this or not\n",
    "\n",
    "```python\n",
    "# The baseline predictions are the historical averages\n",
    "baseline_preds = test_features[:, feature_list.index('average')]\n",
    "# Baseline errors, and display average baseline error\n",
    "baseline_errors = abs(baseline_preds - test_labels)\n",
    "print('Average baseline error: ', round(np.mean(baseline_errors), 2))\n",
    "```\n",
    "\n",
    "5. Run the random forest for training\n",
    "\n",
    "```python\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels);\n",
    "```\n",
    "\n",
    "```python\n",
    "RF = RandomForestClassifier()\n",
    "RF.fit(xTrainFor, yTrainFor)\n",
    "predicted = RF.predict(xTestFor)\n",
    "accuracy = accuracy_score(yTestFor, predicted)\n",
    "\n",
    "print(\"Train Accuracy :: \", accuracy_score(yTrainFor, RF.predict(xTrainFor)))\n",
    "print(\"Test Accuracy  :: \", accuracy_score(yTestFor, predicted))\n",
    "```\n",
    "\n",
    "6. Make predictions\n",
    "```python\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "```\n",
    "7. Calculate Errors:\n",
    "```python\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / test_labels)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')\n",
    "```\n",
    "8. Generate the Confusion matrix:\n",
    "\n",
    "```python\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = pd.DataFrame(confusion_matrix(yTestFor, predicted))\n",
    "sb.heatmap(cm, annot=True)\n",
    "\n",
    "cm = confusion_matrix(test_labels, predictions)\n",
    "plot_confusion_matrix(cm, classes = ['Poor Health', 'Good Health'],\n",
    "                      title = 'Health Confusion Matrix')\n",
    "```\n",
    "\n",
    "9. Visualize a tree from the random forest:\n",
    "```python\n",
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "# Pull out one tree from the forest\n",
    "tree = rf.estimators_[5]\n",
    "# Import tools needed for visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "# Pull out one tree from the forest\n",
    "tree = rf.estimators_[5]\n",
    "# Export the image to a dot file\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "# Use dot file to create a graph\n",
    "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "# Write graph to a png file\n",
    "graph.write_png('tree.png')\n",
    "```\n",
    "\n",
    "10. Smaller Tree version:\n",
    "```python\n",
    "# Limit depth of tree to 3 levels\n",
    "rf_small = RandomForestRegressor(n_estimators=10, max_depth = 3)\n",
    "rf_small.fit(train_features, train_labels)\n",
    "# Extract the small tree\n",
    "tree_small = rf_small.estimators_[5]\n",
    "# Save the tree as a png image\n",
    "export_graphviz(tree_small, out_file = 'small_tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "(graph, ) = pydot.graph_from_dot_file('small_tree.dot')\n",
    "graph.write_png('small_tree.png');\n",
    "```\n",
    "\n",
    "11. Getting Variables of Importance:\n",
    "```python\n",
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA Analysis\n",
    "PCA projects the entire dataset onto a different feature (sub)space, and LDA tries to determine a suitable feature (sub)space in order to distinguish between patterns that belong to different classes.\n",
    "1. Standardize the data\n",
    "```python\n",
    "#Where x are the feature values, and y the target is separated\n",
    "x = StandardScaler().fit_transform(x)\n",
    "```\n",
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seaborn Data Visualization\n",
    "1. Pair wise scatter plots; essentially a covariance matrix of plots and distribution densities\n",
    "```python\n",
    "cols = ['density', 'residual sugar', 'total sulfur dioxide', 'fixed acidity']\n",
    "pp = sns.pairplot(wines[cols], size=1.8, aspect=1.8,\n",
    "                  plot_kws=dict(edgecolor=\"k\", linewidth=0.5),\n",
    "                  diag_kind=\"kde\", diag_kws=dict(shade=True))\n",
    "fig = pp.fig \n",
    "fig.subplots_adjust(top=0.93, wspace=0.3)\n",
    "t = fig.suptitle('Wine Attributes Pairwise Plots', fontsize=14)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotly Charts\n",
    "1. Large Scatter Plot Example:\n",
    "```python\n",
    "trace7 = go.Scattergl(\n",
    "    x = dataDict['defaulted']['creditScore']['Super Prime 781-850+'].sort_values(by=['originalInterestRatePercentage'])['originalInterestRatePercentage'],\n",
    "    name = 'Super Prime 781-850+',\n",
    "    mode='markers',\n",
    "    opacity = 0.7,\n",
    "    marker=dict(\n",
    "        size=6,\n",
    "        #showscale=True,\n",
    "        #colorscale='Blues',\n",
    "        #reversescale=True,\n",
    "        #color=defaulted['obligorCreditScore'],\n",
    "        color = '#2ca02c', #set color equal to a variable\n",
    "    )\n",
    ")\n",
    "```\n",
    "\n",
    "2. Multiple plots in one: Change the layout and add charts where needed:\n",
    "```python\n",
    "fig = tools.make_subplots(rows=3, cols=2, subplot_titles=('Super Prime 781-850+', 'Prime 661 780','Nonprime 601-660', 'Subprime 501-600','Deep Subprime 0-500', 'No Score')\n",
    "fig.append_trace(trace7, 1, 1)\n",
    "fig.append_trace(trace8, 1, 2)\n",
    "fig.append_trace(trace9, 2, 1)\n",
    "fig.append_trace(trace10, 2, 2)\n",
    "fig.append_trace(trace11, 3, 1)\n",
    "fig.append_trace(trace12, 3, 2)\n",
    "fig['layout']['xaxis'].update(dict(tickformat='.0%'))\n",
    "fig['layout']['xaxis2'].update(dict(tickformat='.0%'))\n",
    "fig['layout']['xaxis3'].update(dict(tickformat='.0%'))\n",
    "fig['layout']['xaxis4'].update(dict(tickformat='.0%'))\n",
    "fig['layout']['xaxis5'].update(dict(tickformat='.0%'))\n",
    "fig['layout']['xaxis6'].update(dict(tickformat='.0%'))\n",
    "fig['layout'].update(showlegend=False, height=800, width=1300, title='Paid Down Loans: APR vs Credit Score')\n",
    "```\n",
    "\n",
    "3. Parallel Coordinates: Good for visualizing large multi-dimensional data:\n",
    "\n",
    "```python\n",
    "trace1 = go.Parcoords(\n",
    "    line = dict(color = '#d62728'),\n",
    "    opacity=.5,\n",
    "    dimensions = list([\n",
    "        dict(range = [.0,.3],\n",
    "             label = 'APR', values = defaulted['originalInterestRatePercentage'],\n",
    "            tickformat= \".0%\"),\n",
    "        dict(tickvals = [1, 2, 3, 4, 5, 6],\n",
    "             ticktext = ['No Score','Deep Subprime 0-500','Subprime 501-600','Nonprime 601-660','Prime 661-780', 'Super Prime 781-850+'],\n",
    "             label = 'Credit Score', values = defaulted['CreditScoreCat']\n",
    "            ),\n",
    "    ]),\n",
    "\n",
    ")\n",
    "layout = go.Layout(\n",
    "    title='Defaulted Loans',\n",
    "    hovermode = 'closest',\n",
    ")\n",
    "fig = go.Figure(data = [trace1], layout = layout)\n",
    "```\n",
    "\n",
    "4. Overlay Histogram\n",
    "\n",
    "```python\n",
    "trace1 = go.Histogram(\n",
    "    name='Paid Down',\n",
    "    x=paidDown['obligorCreditScore'][paidDown['obligorCreditScore']>=300],\n",
    "    opacity=0.75,\n",
    "    autobinx=False,\n",
    "    xbins= dict(start=paidDownMin, end=paidDownMax, size=2),\n",
    ")\n",
    "trace2 = go.Histogram(\n",
    "    name='Defaulted',\n",
    "    x=defaulted['obligorCreditScore'][defaulted['obligorCreditScore']>=300],\n",
    "    opacity=0.75,\n",
    "    autobinx=False,\n",
    "    xbins=dict(start=defaultedMin, end=defaultedMax, size=2),\n",
    ")\n",
    "data = [trace1, trace2]\n",
    "layout = go.Layout(barmode='overlay')\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='PaidDown_Defaulted_Overlay_Histogram', sharing='private')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
